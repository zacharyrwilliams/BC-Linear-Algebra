\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}	% Para caracteres en espa√±ol
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}
\usepackage{multirow,booktabs}
\usepackage[table]{xcolor}
\usepackage{fullpage}
\usepackage{lastpage}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{mathrsfs}
\usepackage{wrapfig}
\usepackage{setspace}
\usepackage{calc}
\usepackage{multicol}
\usepackage{cancel}
\usepackage[retainorgcmds]{IEEEtrantools}
\usepackage[margin=3cm]{geometry}
\usepackage{amsmath}
\newlength{\tabcont}
\setlength{\parindent}{0.0in}
\setlength{\parskip}{0.05in}
\usepackage{empheq}
\usepackage{framed}
\usepackage[most]{tcolorbox}
\usepackage{xcolor}
\colorlet{shadecolor}{orange!15}
\parindent 0in
\parskip 12pt
\geometry{margin=1in, headsep=0.25in}
\theoremstyle{definition}
\newtheorem{theorem}{Theorem}
\newtheorem{defn}{Definition}
\newtheorem{reg}{Rule}
\newtheorem{exer}{Exercise}
\newtheorem{note}{Note}

\begin{document}
	\setcounter{section}{0}
	\title{Chapter 1: Matrices}
	
	\thispagestyle{empty}
	
	\begin{center}
		{\LARGE \bf Chapter 1}\\
	\end{center}

	\section{Matrices}
	\subsection{Basic Concepts}
	
	A \textit{matrix} is a rectangular array arranged in vertical columns.
	
	The matrix $L =
	\begin{bmatrix}
	1 & 3 \\
	5 & 2 \\
	0 & -1 \\
	\end{bmatrix} $ is said to have \textit{order} $3$ x $2$.
	
	The entries of a matrix are called \textit{elements}. $l_{1 2}$ refers to the element in the first row and second column of the matrix $L$.
	
	In general, a matrix $A$ of order $p$x$n$ has the form $A = \begin{bmatrix}
	a_{11} & a_{12} & \dots & a_{1n} \\
	a_{21} & a_{22} & \dots & a_{2n|} \\
	\vdots & \vdots & \ddots & \vdots \\
	a_{p1} & a_{p2} & \dots & a_{pn}
	\end{bmatrix} $
	
	Any element having its row index equal to its column index is a \textit{diagonal element}.
	
	A matrix is \textit{square} if it has the same number of rows as columns. In a square matrix, the elements $a_{11}, a_{22}, a_{33}, \dots$ form the \textit{main} or \textit{principal} diagonal.
	
	The elements of a matrix need not be numbers; they can be functions or matrices themselves.
	
	A \textit{row matrix} is a matrix having a single row; a \textit{column matrix} is a matrix having a single column. The elements of such a matrix are commonly called its \textit{components}, and the number of components its \textit{dimension}. 
	
	The term \textit{n-tuple} refers to either a row matrix or a column matrix having dimension $n$. 
	
	Two matrices $A$ and $B$ are \textit{equal} if they have the same order and if their correspondng elements are equal.
	
	\textit{The sum of two matrices of the same order} is a matrix obtained by adding together corresponding elements of the original matrices. Addition is not defined for matrices of different orders.
	
	\begin{theorem}
		If matrices $A$, $B$, $C$ all have the same order, then 
		
		\begin{enumerate}[label=(\alph*)]
			\item the commutative law of addition holds; that is, $A + B = B + A$
			\item the associative law of addition holds; that is, $A + (B  + C) = (A + B) + C$
		\end{enumerate}
	\end{theorem}
	
	\begin{shaded}
		\begin{proof}
			\begin{enumerate}[label=(\alph*)]
				\item Let $A = [a_{ij}] \land B = [b_{ij}]$. Then
				\begin{align*}
				A + B = [a_{ij}] + [b_{ij}] && \text{by defs. of A, B} \\
				= [a_{ij}] + [b_{ij}] && \text{by def. of matrix addition} \\
				= [b_{ij} + a_{ij}] && \text{by commutative property of addition} \\
				= [b_{ij}] + [a_{ij}] && \text{by def. of matrix addition} \\
				= B + A
				\end{align*}
				
				\item Let $A = [a_{ij}], B = [b_{ij}],$ and $C = [c_{ij}]$. Then
				\begin{align*}
				A + (B + C) = [a_{ij}] + ([b_{ij}] + [c_{ij}]) \\
				= [a_{ij}] + [b_{ij} + c_{ij}] && \text{by def. of matrix addition} \\
				= [a_{ij} + (b_{ij} + c_{ij})] && \text{by def. of matrix addition} \\
				= [(a_{ij} + b_{ij}) + c_{ij}] && \text{by associative property of addition} \\
				= [(a_{ij} + b_{ij})] + [c_{ij}] && \text{by def. of matrix addition}
				= (A + B) + C
				\end{align*} 
			\end{enumerate}
		\end{proof}
	\end{shaded}

	We define the matrix $0$ to be a matrix consisting of only zero elements. When a zero matrix has the same order as another matrix $A$, we have the additional property $A + 0 = A$.
	
	Subtraction of matrices is defined analogously to addition. The difference $B - A$ of two matrices of the same order is the matrix obtained by subtracting from the elements of $A$ the corresponding elements of $B$.
	
	A matrix $A$ can always be added to itself, forming the sum $A + A$. We would like to write $A + A = 2A$.
	
	The right side of the equation is a number times a matrix, a product known as \textit{scalar multiplication}.
	
	If $A = [a_{ij}] $ is a $p$x$n$ matrix and if $\lambda$ is a real number, then $ \lambda A = [\lambda a_{ij}], (i=1,2,\dots,p; j=1,2,\dots,n).$
	
	\begin{theorem}
		If $A \land B$ are matrices of the same order and if $\lambda_1 \land \lambda_2$ denote scalars, then the following distributive laws hold: 
		
		\begin{enumerate}[label=(\alph*)]
			\item $\lambda_1 (A+B) = \lambda_1A + \lambda_1B.$
			\item $(\lambda_1 + \lambda_2)A = \lambda_1A + \lambda_2A$
			\item $(\lambda_1\lambda_2)A = \lambda_1(\lambda_2A)$
		\end{enumerate}
	\end{theorem}

	\begin{shaded}
		\begin{proof}
			\begin{enumerate}[label=(\alph*)]
				\item Let $A = [a_{ij}] \land B = [b_{ij}]$. Then
				\begin{align*}
					\lambda_1(A+B) = \lambda_1([a_{ij}] + [b_{ij}]) \\
					= \lambda_1[(a_{ij} + b_{ij})] && \text{def. of matrix addition} \\
					= [\lambda_1(a_{ij} + b_{ij})] && \text{def. of scalar multiplication} \\
					= [(\lambda_1a_{ij} + \lambda_1b_{ij})] && \text{distributive property of scalars} \\
					= [\lambda_1a_{ij}] + [\lambda_1b_{ij}] && \text{def. of matrix addition} \\
					= \lambda_1[a_{ij}] + \lambda_1[b_{ij}] && \text{def. of scalar multiplication}
					= \lambda_1A + \lambda_1B
				\end{align*}
				
				\item Let $A = [a_{ij}]$. Then
				\begin{align*}
					(\lambda_1+\lambda_2)A = (\lambda_1+\lambda_2)[a_{ij}]\\
					= [(\lambda_1+\lambda_2)a_{ij}] && \text{def. of scalar multiplication} \\
					= [\lambda_1a_{ij} + \lambda_2a_{ij}] && \text{distributive property of multiplication} \\
					= [\lambda_1a_{ij}] + [\lambda_2a_{ij}] && \text{def. of matrix addition} \\
					= \lambda_1[a_{ij}] + \lambda_2[a_{ij}] && \text{def. of scalar multiplication} \\
					= \lambda_1A + \lambda_2A
				\end{align*} 
				
				\item Let $A = [a_{ij}]$. Then 
				\begin{align*}
					(\lambda_1\lambda_2)A = (\lambda_1\lambda_2)[a_{ij}] \\
					= [(\lambda_1\lambda_2)a_{ij}] && \text{def. of scalar multiplication} \\
					= [\lambda_1(\lambda_2a_{ij})] && \text{associative property of multiplication} \\
					= \lambda_1[\lambda_2a_{ij}] && \text{def. of scalar multiplication} \\
					= \lambda_1(\lambda_2A)
				\end{align*}
			\end{enumerate}
		\end{proof}
	\end{shaded}

	\subsection{Matrix Multiplication}
		A single system of two linear equations in two unknowns is 
		\begin{align*}
			2x + 3y = 10 \\
			4x + 5y = 20
		\end{align*}
		
		Combining all the coefficients of the variables on the left of each equation into a \textit{coefficient matrix}, all the variables into a column matrix of variables; and the constants on the right of each equation into another column matrix, we separate the matrix system
		\begin{center}
			$\begin{bmatrix}
			2 & 3 \\ 4 & 5
			\end{bmatrix}
			\begin{bmatrix}
			x \\ y
			\end{bmatrix}
			= \begin{bmatrix}
			10 \\ 20
			\end{bmatrix}$
		\end{center}
		
		We want to define matrix multiplication so that 
		\begin{center}
			$\begin{bmatrix}
			2 & 3 \\ 4 & 5
			\end{bmatrix}
			\begin{bmatrix}
			x \\ y
			\end{bmatrix}
			=\begin{bmatrix}
			(2x + 3y) \\ (4x + 5y)
			\end{bmatrix}
			= \begin{bmatrix}
			10 \\ 20
			\end{bmatrix}$
		\end{center}
	
		We shall define the product $AB$ of two matrices $A$ and $B$ when the number of columns of $A$ is equal to the number of rows of $B$, and the result will be a matrix having the same number of rows as A and the same number of columns as B.
		
		When the product $AB$ is considered, $A$ is said to \textit{premultiply} $B$, while $B$ is said to \textit{postmultiply} $A$.
		
		To calculate the $i-j$ element of $AB$, when the multiplication is defined, multiply the elements in the $i$th row of $A$ by the corresponding elements in the $j$th column of $B$ and sum the results.
		
		Let $AB = C = [c_{ij}]$. Then $[c_{ij}] = a_{i1}b_{1j} + a_{i2}b_{2j} + \dots + a_{ir}b_{rj} = \sum\limits_{k=1}^{r} a_{ik}b_{kj}$.
		
		Although matrix multiplication is not commutative, some matrix products are. Also, matrices exist for which $AB = 0$ without either $A$ or $B$ being $0$. The cancellation law also does not apply. In general, $AB = AC$ does not imply $B = C$.	
		
		\begin{theorem}
			If $A, B, \land C$ have appropriate orders so that the following additions and multiplications are defined, then
			\begin{enumerate}[label=(\alph*)]
				\item $A(BC) = (AB) C$ \hfill (associative law of multiplication)
				\item $A(B+C) = AB + AC$ \hfill (left distributive law)
				\item $(B+C)A = BA + CA$ \hfill (right distributive law)
			\end{enumerate}
		\end{theorem}
		
		\begin{shaded}
			\begin{proof}
				\begin{enumerate}[label=(\alph*)]
					\item Let $A = [a_{ij}]$ be an $m$x$n$ matrix, $B = [b_{ij}]$ be an $n$x$p$ matrix, and $C=[c_{ij}]$ be a $p$x$q$ matrix. Then
					\begin{align*}
						(AB)C = ([a_{ij}][b_{jk}])[c_{}] \\
						= (\sum\limits_{k=1}^{r} a_{ik}b_{kj})[c_{}] \\
						= \sum\limits_{l=1}^{p}(\sum\limits_{k=1}^{r} a_{ik}b_{kj})c_{} \\
						= \sum\limits_{l}([ab]_{il}[c]_{}) \\
						= [ab]_{il}[c]_{lj} \\
						= (AB)C
					\end{align*}
					
					\begin{note}
						I got lost in the sea of subscripts, but labeled appropriately (and arbitrarily) the logic still holds.
					\end{note}
					
					\item Let $A = [a_{ij}] \land B = [b_{ij}] \land C = [c_{ij}]$, where $A$ is $m$x$n$, and $B$ and $C$ are $n$x$p$. Then
					\begin{align*}
						A(B+C) = [a_{ij}]([b_{ij}] + [c_{ij}]) \\
						= [a_{ij}][(b_{ij} + c_{ij})] \\
						= \sum\limits_{k}a_{ik}(b_{kj}+c_{kj}) \\
						= \sum\limits_{k}a_{ik}b_{kj} + a_{ik}c_{kj} \\
						= \sum\limits_{k}a_{ik}b_{kj} + \sum\limits_{k}a_{ik}c_{kj} \\
						= [a_{ij}][b_{ij}] + [a_{ij}][c_{ij}] \\
						= AB + AC
					\end{align*} 
					
					\item Let $A = [a_{ij}] \land B = [b_{ij}] \land C = [c_{ij}]$, where $A$ is $m$x$n$, and $B$ and $C$ are $n$x$p$. Then
					\begin{align*}
						(B+C)A = ([b_{ij}] + [c_{ij}])[a_{ij}] \\
						= \sum\limits_{k}(b_{ik} + c_{ik})a_{kj} \\
						= \sum\limits_{k}(b_{ik}a_{kj} + c_{ik})a_{kj} \\
						= \sum\limits_{k}(b_{ik}a_{kj} + \sum\limits_{k}c_{ik})a_{kj} \\
						= BA + BC
					\end{align*}
				\end{enumerate}
			\end{proof}
		\end{shaded}
\end{document}

